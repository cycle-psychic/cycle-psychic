{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import pandas and scikitlearn for Machine Learning Models\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, HuberRegressor, ElasticNetCV\n",
    "from sklearn.ensemble import BaggingRegressor, ExtraTreesRegressor, GradientBoostingRegressor, RandomForestRegressor\n",
    "\n",
    "# Pickle saves the model\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in cleaned results\n",
    "df = pd.read_csv('05-13-03-19_station2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Transform to a 2D array and assign features and target\n",
    "# Available bikes as target. Another model can be done for available stands if needed.\n",
    "features = df[['number', 'weekday', 'hour', 'minute']].values\n",
    "targets = df['available_bikes'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cycles through neural network options and selects the most accurate.\n",
    "def mlp_regressor_grid_search():\n",
    "    est = MLPRegressor(activation= 'logistic')\n",
    "    sizes = []\n",
    "    for size1 in range(5, 20, 5):\n",
    "        sizes.append(size1)\n",
    "\n",
    "    param_grid = dict(solver=['lbfgs'], #'sgd','adam'\n",
    "                      learning_rate=['adaptive','invscaling'],\n",
    "                      alpha=[0.0001], # [0.0005, 0.001, 0.005, 0.01]\n",
    "                      max_iter=[200], #np.arange(200, 300, 20)\n",
    "                      tol=[0.0001], #np.arange(0.00001, 0.0001, 0.00001)\n",
    "                      hidden_layer_sizes=sizes)\n",
    "    return GridSearchCV(est, param_grid=param_grid, n_jobs=1, verbose=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [LinearRegression(),\n",
    "          Ridge(),\n",
    "          HuberRegressor(),\n",
    "          ElasticNetCV(),\n",
    "          DecisionTreeRegressor(), \n",
    "          ExtraTreesRegressor(),\n",
    "          GradientBoostingRegressor(),\n",
    "          RandomForestRegressor(),\n",
    "          BaggingRegressor()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data set into test and training data.\n",
    "def split_by_position(features, targets):\n",
    "    \"\"\"\n",
    "    train 0.80\n",
    "    test 0.20\n",
    "    \"\"\"\n",
    "    len_train = int(0.80 * len(features))\n",
    "    train_features = features[0:len_train]\n",
    "    train_targets = targets[0:len_train]\n",
    "    test_features = features[len_train:]\n",
    "    test_targets = targets[len_train:]\n",
    "    return train_features, test_features, train_targets, test_targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign training features and target and test features and target\n",
    "train_features, test_features, train_targets, test_targets = split_by_position(features, targets)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# Normalise the features for training\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_features)\n",
    "scaled_train_features = scaler.transform(train_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[CV] alpha=0.0001, hidden_layer_sizes=5, learning_rate=adaptive, max_iter=200, solver=lbfgs, tol=0.0001 \n",
      "[CV]  alpha=0.0001, hidden_layer_sizes=5, learning_rate=adaptive, max_iter=200, solver=lbfgs, tol=0.0001, score=-1.8914202777676041, total=   0.1s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[CV] alpha=0.0001, hidden_layer_sizes=5, learning_rate=adaptive, max_iter=200, solver=lbfgs, tol=0.0001 \n",
      "[CV]  alpha=0.0001, hidden_layer_sizes=5, learning_rate=adaptive, max_iter=200, solver=lbfgs, tol=0.0001, score=-0.9208305092120043, total=   0.1s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.2s remaining:    0.0s\n",
      "[CV] alpha=0.0001, hidden_layer_sizes=5, learning_rate=adaptive, max_iter=200, solver=lbfgs, tol=0.0001 \n",
      "[CV]  alpha=0.0001, hidden_layer_sizes=5, learning_rate=adaptive, max_iter=200, solver=lbfgs, tol=0.0001, score=-7.613697050228135, total=   0.1s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.2s remaining:    0.0s\n",
      "[CV] alpha=0.0001, hidden_layer_sizes=5, learning_rate=invscaling, max_iter=200, solver=lbfgs, tol=0.0001 \n",
      "[CV]  alpha=0.0001, hidden_layer_sizes=5, learning_rate=invscaling, max_iter=200, solver=lbfgs, tol=0.0001, score=-0.31705346675838997, total=   0.1s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.3s remaining:    0.0s\n",
      "[CV] alpha=0.0001, hidden_layer_sizes=5, learning_rate=invscaling, max_iter=200, solver=lbfgs, tol=0.0001 \n",
      "[CV]  alpha=0.0001, hidden_layer_sizes=5, learning_rate=invscaling, max_iter=200, solver=lbfgs, tol=0.0001, score=0.4481432602172752, total=   0.1s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s remaining:    0.0s\n",
      "[CV] alpha=0.0001, hidden_layer_sizes=5, learning_rate=invscaling, max_iter=200, solver=lbfgs, tol=0.0001 \n",
      "[CV]  alpha=0.0001, hidden_layer_sizes=5, learning_rate=invscaling, max_iter=200, solver=lbfgs, tol=0.0001, score=-6.3655607120510185, total=   0.1s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.5s remaining:    0.0s\n",
      "[CV] alpha=0.0001, hidden_layer_sizes=10, learning_rate=adaptive, max_iter=200, solver=lbfgs, tol=0.0001 \n",
      "[CV]  alpha=0.0001, hidden_layer_sizes=10, learning_rate=adaptive, max_iter=200, solver=lbfgs, tol=0.0001, score=-1.84480600735544, total=   0.1s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.6s remaining:    0.0s\n",
      "[CV] alpha=0.0001, hidden_layer_sizes=10, learning_rate=adaptive, max_iter=200, solver=lbfgs, tol=0.0001 \n",
      "[CV]  alpha=0.0001, hidden_layer_sizes=10, learning_rate=adaptive, max_iter=200, solver=lbfgs, tol=0.0001, score=0.5799122669300847, total=   0.1s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.6s remaining:    0.0s\n",
      "[CV] alpha=0.0001, hidden_layer_sizes=10, learning_rate=adaptive, max_iter=200, solver=lbfgs, tol=0.0001 \n",
      "[CV]  alpha=0.0001, hidden_layer_sizes=10, learning_rate=adaptive, max_iter=200, solver=lbfgs, tol=0.0001, score=-21.95209755088995, total=   0.1s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.7s remaining:    0.0s\n",
      "[CV] alpha=0.0001, hidden_layer_sizes=10, learning_rate=invscaling, max_iter=200, solver=lbfgs, tol=0.0001 \n",
      "[CV]  alpha=0.0001, hidden_layer_sizes=10, learning_rate=invscaling, max_iter=200, solver=lbfgs, tol=0.0001, score=-0.10924233257879701, total=   0.1s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.8s remaining:    0.0s\n",
      "[CV] alpha=0.0001, hidden_layer_sizes=10, learning_rate=invscaling, max_iter=200, solver=lbfgs, tol=0.0001 \n",
      "[CV]  alpha=0.0001, hidden_layer_sizes=10, learning_rate=invscaling, max_iter=200, solver=lbfgs, tol=0.0001, score=0.42572228909349585, total=   0.1s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.9s remaining:    0.0s\n",
      "[CV] alpha=0.0001, hidden_layer_sizes=10, learning_rate=invscaling, max_iter=200, solver=lbfgs, tol=0.0001 \n",
      "[CV]  alpha=0.0001, hidden_layer_sizes=10, learning_rate=invscaling, max_iter=200, solver=lbfgs, tol=0.0001, score=-11.40231782146031, total=   0.1s\n",
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:    1.0s remaining:    0.0s\n",
      "[CV] alpha=0.0001, hidden_layer_sizes=15, learning_rate=adaptive, max_iter=200, solver=lbfgs, tol=0.0001 \n",
      "[CV]  alpha=0.0001, hidden_layer_sizes=15, learning_rate=adaptive, max_iter=200, solver=lbfgs, tol=0.0001, score=-1.4538910861314895, total=   0.1s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    1.1s remaining:    0.0s\n",
      "[CV] alpha=0.0001, hidden_layer_sizes=15, learning_rate=adaptive, max_iter=200, solver=lbfgs, tol=0.0001 \n",
      "[CV]  alpha=0.0001, hidden_layer_sizes=15, learning_rate=adaptive, max_iter=200, solver=lbfgs, tol=0.0001, score=0.5556787226922212, total=   0.1s\n",
      "[Parallel(n_jobs=1)]: Done  14 out of  14 | elapsed:    1.2s remaining:    0.0s\n",
      "[CV] alpha=0.0001, hidden_layer_sizes=15, learning_rate=adaptive, max_iter=200, solver=lbfgs, tol=0.0001 \n",
      "[CV]  alpha=0.0001, hidden_layer_sizes=15, learning_rate=adaptive, max_iter=200, solver=lbfgs, tol=0.0001, score=-10.53423878421587, total=   0.1s\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    1.3s remaining:    0.0s\n",
      "[CV] alpha=0.0001, hidden_layer_sizes=15, learning_rate=invscaling, max_iter=200, solver=lbfgs, tol=0.0001 \n",
      "[CV]  alpha=0.0001, hidden_layer_sizes=15, learning_rate=invscaling, max_iter=200, solver=lbfgs, tol=0.0001, score=0.2970675467023163, total=   0.1s\n",
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:    1.4s remaining:    0.0s\n",
      "[CV] alpha=0.0001, hidden_layer_sizes=15, learning_rate=invscaling, max_iter=200, solver=lbfgs, tol=0.0001 \n",
      "[CV]  alpha=0.0001, hidden_layer_sizes=15, learning_rate=invscaling, max_iter=200, solver=lbfgs, tol=0.0001, score=0.2477385243359198, total=   0.1s\n",
      "[Parallel(n_jobs=1)]: Done  17 out of  17 | elapsed:    1.5s remaining:    0.0s\n",
      "[CV] alpha=0.0001, hidden_layer_sizes=15, learning_rate=invscaling, max_iter=200, solver=lbfgs, tol=0.0001 \n",
      "[CV]  alpha=0.0001, hidden_layer_sizes=15, learning_rate=invscaling, max_iter=200, solver=lbfgs, tol=0.0001, score=-9.981005419734519, total=   0.1s\n",
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:    1.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:    1.6s finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=MLPRegressor(activation='logistic', alpha=0.0001, batch_size='auto',\n",
       "       beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=1,\n",
       "       param_grid={'solver': ['lbfgs'], 'learning_rate': ['adaptive', 'invscaling'], 'alpha': [0.0001], 'max_iter': [200], 'tol': [0.0001], 'hidden_layer_sizes': [5, 10, 15]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=100)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tests training features and targets with different neural network options\n",
    "est = mlp_regressor_grid_search()\n",
    "est.fit(scaled_train_features, train_targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPRegressor(activation='logistic', alpha=0.0001, batch_size='auto',\n",
      "       beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=5, learning_rate='invscaling',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=None, shuffle=True, solver='lbfgs', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "# Print best hyper parameters for model\n",
    "print(est.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6449067298301492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# Print score for best estimator on test data\n",
    "print(est.score(scaler.transform(test_features), test_targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.13100233771649616\n",
      "-0.1308276657796692\n",
      "-0.14799966782928897\n",
      "-0.09486833649783666\n",
      "0.5176025936045243\n",
      "0.5109056191753276\n",
      "0.5333341085897598\n",
      "0.5356191559686072\n",
      "0.5300990992851324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# Test algorithms for performance.\n",
    "for model in models:\n",
    "    est = model\n",
    "    est.fit(scaled_train_features, train_targets)\n",
    "    print(est.score(scaler.transform(test_features), test_targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTION: [0.2]\n"
     ]
    }
   ],
   "source": [
    "# Use features to print a prediction\n",
    "predict_data = [[2.0,2.0,8.0,44.0]]\n",
    "scaled_predict = scaler.transform(predict_data)\n",
    "\n",
    "\n",
    "prediction = est.predict(scaled_predict)\n",
    "print(\"PREDICTION:\", math.floor(prediction))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Using elastic net CV as seems to be the best fit currently\n",
    "# Pickle saves the model\n",
    "est = ElasticNetCV()\n",
    "est.fit(scaled_train_features, train_targets)\n",
    "filename_est = 'model.sav'\n",
    "filename_scaler = 'scaler.sav'\n",
    "pickle.dump(est, open(filename_est, 'wb'))\n",
    "pickle.dump(scaler, open(filename_scaler, 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
